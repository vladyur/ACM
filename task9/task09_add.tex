\documentclass[10pt,twocolumn]{article}
\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,wrapfig}
%,wrapfig}
\usepackage{epsfig}
\usepackage{amssymb}
\textheight=250mm
\textwidth=186mm
\hoffset=-8mm
\voffset=-28mm
\pagestyle{empty}
%\title{ ЗАДАНИЕ 1: ИНДУКЦИЯ, ЯЗЫКИ ДИКА (СКОБОЧНЫХ ВЫРАЖЕНИЙ)}
%\title{
%\author{}
\let\empty\varnothing
\let\ph\varphi
\let\eps\varepsilon
\def\D{{\cal D}}
\def\E{{\cal E}}
\def\T{{\cal T}}
\def\L{{\cal L}}
\def\F{{\cal F}}
\def\Q{{\cal Q}}
\def\N{{\cal N}}
\def\M{{\cal M}}
\def\bM{{\bf M}}
\def\bA{{\bf A}}
\def\A{{\cal A}}
\def\B{{\cal B}}
\def\C{{\cal C}}
\def\p{{\cal P}}
\def\U{{\cal U}}
\def\W{{\cal W}}
\def\H{{\cal H}}
\def\R{\cal R}
\def\np{{\cal NP}}
\def\psp{{\cal PSPACE}}
\def\bp{{\cal BPP}}
\def\rp{{\cal RP}}
\def\zp{{\cal ZPP}}
\def\DD{{\mathbb D}}
\def\f{\tilde f}
\def\EE{{\mathbb E}}
\def\PP{{\mathbb P}}
%\def\ZZ{{\mathbb Z}}
%\def\RR{\mathbb R} 
\def\ind{\mathop{\rm index}}
\def\St{\mathop{\rm St}}
\def\Poly{\mathop{\rm poly}\nolimits}
\let\bd\partial
\def\V{\ensuremath{{\cal V}}}
\def\SS{{\mathbb S}}
\def\RR{\mathbb R}
\def\CC{\mathbb C}
\def\ZZ{\mathbb Z}
\def\NN{\mathbb N}
\def\zam{{\bfЗамечание для семинаристов.}}
\def\ss{\Sigma^* }
\newtheorem{Definition}{Определение}
\newtheorem{Theorem}{Теорема}
\newtheorem{Lemma}{Лемма}
\renewcommand{\figurename}{Рис.}

\newcommand{\Rnum}[1]{\expandafter{\romannumeral #1\relax}}
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

\newcounter{problem}
\newcounter{extraproblem}
\newcounter{uproblem}
\newcounter{subproblem}
\newcounter{prvar}
\def\pr{\medskip\noindent\stepcounter{problem}{\bf \theproblem .  }\setcounter{subproblem}{0} }
\def\prstar{\medskip\noindent\stepcounter{problem}{\bf $\mathbf{\theproblem}^*$\negthickspace.  }\setcounter{subproblem}{0} }
\def\prpfrom[#1]{\medskip\noindent\stepcounter{problem}{\bf Задача \theproblem~(№#1 из задания).  }\setcounter{subproblem}{0} }
\def\prp{\medskip\noindent\stepcounter{problem}{\bf Задача \theproblem .  }\setcounter{subproblem}{0} }
\def\extraprp{\medskip\noindent\stepcounter{extraproblem}{\bf Задача Д--\theextraproblem .  }\setcounter{subproblem}{0} }
%
\def\myprsub{\medskip\noindent\stepcounter{subproblem}{\bf Задача \theproblem . \thesubproblem .  } }
\def\myextraprsub{\medskip\noindent\stepcounter{subproblem}{\bf Задача Д--\theextraproblem .  \thesubproblem .  } } 
%
\def\prpvar{\medskip\noindent\stepcounter{problem}\setcounter{prvar}{1}{\bf Задача \theproblem \;({\rm\Rnum{\theprvar}}).  }\setcounter{subproblem}{0} }
\def\prpv{\medskip\noindent\stepcounter{prvar}{\bf Задача \theproblem \;({\rm\Rnum{\theprvar}}).  }\setcounter{subproblem}{0} }

\def\prpstar{\medskip\noindent\stepcounter{problem}{\bf Задача $\bf\theproblem^*$\negthickspace.  }\setcounter{subproblem}{0} }
\def\prdag{\medskip\noindent\stepcounter{problem}{\bf Задача $\theproblem^{^\dagger}$\negthickspace\,.  }\setcounter{subproblem}{0} }
\def\upr{\medskip\noindent\stepcounter{uproblem}{\bf Упражнение \theuproblem .  }\setcounter{subproblem}{0} }
%\def\prp{\vspace{5pt}\stepcounter{problem}{\bf Задача \theproblem .  } }
%\def\prs{\vspace{5pt}\stepcounter{problem}{\bf \theproblem .*   }
\def\prsub{\medskip\noindent\stepcounter{subproblem}{\rm \thesubproblem .  } }
\def\prsubr{\medskip\noindent\stepcounter{subproblem}{\rm \thesubproblem)  } }
\def\prsubstar{\medskip\noindent\stepcounter{subproblem}{\rm $\thesubproblem^*$\negthickspace.  } }
\def\prsubrstar{\medskip\noindent\stepcounter{subproblem}{\rm $\thesubproblem^*$)  } }  

\newcommand{\romb}[3]{
\put(#1,#2){\circle*{1}}
\put(#3,#2){\circle*{1}}
\put(#1,#2){\line(1,1){5}}
\put(#3,#2){\line(-1,-1){5}}
\put(#3,#2){\line(-1,1){5}}
} 

%\def\theenumi{\roman{enumi}}

\begin{document}
%\maketitle



{\footnotesize 



\centerline{\bf  Вероятностные алгоритмы}
\centerline{\bf Разделы 12 программы}
\centerline{\bf Литература:  [Кормен 2, \S 5 и дополнение C]}
\centerline{\bf [Кормен 1,  \S 6 ], [GL], [ДПВ ], [К-Ф], [К-Ш-В]}






%{\footnotesize

\medskip

\centerline{\bf Краткий конспект}


\smallskip



{\bf В этом задании мы рассмотрим процедуры,
использующие {\em рандомизацию}. 
%Их не надо путать с алгоритмами,
%в которых вероятностные соображения привлекаются при анализе трудоемкости на ``случайном входе''
%(типа QUICKSORT). 
Но мы не будем  делать  {\em  никаких априорных предположений о входном распределении},
}
%и рассматриваем трудоемкость по наихудшему случаю}. 


Мы уже обсуждали  как минимум три подобные процедуры (быструю сортировку, поиск медианы и проверку простоты), использующие бросание монетки (вероятностный алгоритм)
и перейдем теперь к их формальному описанию. К сожалению, из-за недостатка времени мы успеем только ознакомиться
 с определениями и решить несколько задач. Но можно  без преувеличения сказать, что вероятностные
подходы к алгоритмам являются стержнем многих современных исследований\footnote{Достаточно посмотреть на изменения,
внесенных во 2-е издание Кормена.}. Представить без них мир алгоритмов совершенно 
невозможно, так что всем заинтересованым лицам будет нелишне продолжить изучение этого подхода самостоятельно.

И основной лозунг, под которым оформлено это задание звучит так.

\emph{К возможности использования случайных битов нужно относиться как к дополнительному
вычислительному ресурсу, позволяющему иногда существенно понизить трудоемкость и концептуально упростить 
процедуру.
}

Основным источником таких возможностей является (гипотетическая) возможность алгоритмического порождения ``случайных объектов'' в конкретных
``универсумах'', так сказать, ``псевдослучайные генераторы''. Мы будем использовать простейшие варианты: 
``орлянку'', выбор случайного натурального
числа на отрезке $[1,N]$, выбор случайного ребра в графе, выбор случайной плоскости, проходящей через начало
координат и т.д. 
Практически это рутинные программистские операции, используемые часто рефлекторно.
Хотя даже на практическом уровне серьезно обсуждаются вопросы о качестве этих генераторов.

В соответствие с идеологией нашего курса, в идеале, в каждом случае, когда нам
нужно породить ``случайный объект'', мы должны указывать конкретную процедуру порождения,
уметь проверять (доказывать), что она действительно порождает нужные объекты, и 
уметь оценивать ее трудоемкость. Хочу отметить, что
эти вопросы достаточно тонкие и, более того, многие из них пока не имеют удовлетворительных ответов.
\smallskip

{\em Вероятностная} Машина Тьюринга (ВМТ) представляет из себя обычную МТ, 
которой в некоторых состояния
разрешено совершать переходы в зависимости от бросания монеты. 
В отличии от недетерминированной МТ легко представить себе практическую реализацию
такой конструкции.
Более того, как утверждают некоторые апологеты теории вероятностей, иных устройств в природе просто не
существует. Будем считать, что используются стандартные монетки для игры в орлянку\footnote{Монетки
у которых, скажем, вероятность выпадения герба является каким-нибудь {\em невычислимым} числом, в
принципе можно использовать, для распознавания невычислимых языков.}, так что каждое вычисление 
ВМТ на входе $x$ полностью определено, если считать (по аналогии с определением класса $\np$), что 
одновременно с $x$ на вход детерминированной МТ
подается (вообще говоря, бесконечное) $\{0,1\}$-слово. 

Как определить, что слово или язык принимается ВМТ? 

В соответствии с определением ВМТ любое 
вычисление имеет некоторую вероятность. 

Будем говорить, что язык $L \subset \ss$ принимается ВМТ $M$
в {\em СЛАБОМ  смысле [по стандарту МОНТЕ-КАРЛО]}, если для любого слова $x \in \ss$ 
вероятность получения ошибочного ответа на вопрос: ($x \in L$?) не превосходит $\frac13$. Иначе говоря,
если $x \in L$,  то $M$ с вероятностью, не меньшей $\frac23$ ПРИНИМАЕТ $x$; а если 
$x \notin L$,  то $M$ с вероятностью, не меньшей $\frac23$ ОТВЕРГАЕТ $x$.

Будем говорить, что язык $L \subset \ss$ принимается ВМТ $M$
в {\em СИЛЬНОМ  смысле [по стандарту ЛАС-ВЕГАС]}, если она дает {\em с вероятностью $1$} 
правильный ответ для любого слова $x \in \ss$. Это, в частности, означает, что $M$ не может за конечное
число шагов принять какое-нибудь слово $x \notin L$.

Языки, принимаемые ВМТ в СЛАБОМ смысле за {\em полиномиальное в среднем число шагов}, образуют класс $\bp$.

Языки, принимаемые ВМТ в СИЛЬНОМ смысле за {\em полиномиальное в среднем число шагов}, образуют класс $\zp$.


Наконец, языки, для которых удается построить ВМТ, которая за полиномиальное в среднем число шагов принимает
каждое слово из языка с вероятностью $\geq \frac12$ и 
отвергает любое слово, не входящее в язык, образуют промежуточный класс $\rp$.

По построению, классы $\bp$ и $\zp$ замкнуты относительно дополнения и $\bp \supseteq \rp \supseteq \zp 
\supseteq \p$. В основном, мы будем изучать $\bp$. Рекомендую почитать  книгу Кузюрина и Фомина (гл. 4--5, \S 6.2) или книгу  ``Классические и
квантовые вычисления''. В последней, в разделах 1.3-1.4 дано определение класса $\bp$, приведен вероятностный тест 
простоты Миллера-Рабина,
показано, что $\bp \subset \Sigma^p_1 \cap \Pi^p_1$ (т.е. принадежит второму этажу т.н. полиномиальной иерархии).
В разделе 12.2 построена вероятностная полиномиальная сводимость (что бы  это значило?) 
вычисления дискретного логарифма (а это, что такое?) к задаче 
разложения числа на множители (задаче факторизации). 
Кроме того, сами квантовые вычисления
являются аналогом вероятностных вычислений со специально определенным правилом вычисления вероятности.
При этом, однако, оказывается, что квантовые компьютеры позволяют решать, например,
задачу факторизации за полиномиальное время. Как известно, никто пока не знает, есть ли полиномиальный
(детерминированный или вероятностный) классический алгоритм для этой задачи. Кроме того, никто пока
не умеет решать на квантовом компьютере какую-нибудь $NP$-полную задачу за полиномиальное время.
}


\prp ($0.01+0.01$)
Покажите, что
класс $\bp$ не изменится, если 

\noindent ($i$) константу стандарта 
Монте-Карло 
$\frac13$  заменить на любое число, строго меньшее
$\frac12$, а 

\noindent ($ii$)
{\bf полиномиальное в среднем число шагов}
заменить на {\bf полиномиальное число шагов}.


\smallskip

{\footnotesize
Последняя задача
позволяет дать определение класса $\bp$ по аналогии с классом $\np$.

{\em Предикат   $L$ принадлежит классу $\bp$, если
существуют такие  полином
$q(\cdot)$ и предикат $ R(\cdot,\cdot)\in\p$, что\\[3pt]
\begin{tabular}{@{}c@{\hskip5mm}c@{\hskip5mm}p{60mm}@{}}
 $L(x)=1$&$ \Longrightarrow$& доля слов $r$  длины $ q(|x|)$,
для которых выпол\-не\-но $ R(x,r)$, больше $2/3$;\\
 $L(x)=0$&$ \Longrightarrow$& доля слов $r$  длины $ q(|x|)$,
для которых выпол\-не\-но $ R(x,r)$, меньше $1/3$.
\end{tabular}
}

Иначе говоря, на вход недетерминированной МТ подается слово-вход $x$ и слово-подсказка $r$, и 
$x$ принимается, если и только если при некоторой (не слишком длинной) подсказке принимается пара $(x,r)$.
Соответственно, ВМТ читает слово-вход $x$, а роль слова-подсказки $r$ выполняют результаты бросания монетки
в процессе вычисления, причем слово $x$ принадлежит языку,
если пары $(x,r)$ принимаются для фиксированной доли $C_1$ подсказок (бросаний монеты) и отвергается,
если число допустимых пар $(x,r)$ меньше некоторой фиксированой доли $C_2$. По определению, константы 
$C_1$ и $C_2$ должны иметь ``зазор'' $C_1-C_2>\eps$. Если последнее требование опустить (т. е. положить
$C_1=C_2=\frac12$), то вычислительные
возможности ВМТ неизмеримо возрастают, а класс распознаваемых на таких ВМТ языков 
называется ${\cal PP}$.
В частности, $\np \subseteq {\cal PP}$.

\smallskip

Проверка (полиномиальных) тождеств является одним из наглядных и убедительных примеров нетривиального
использования вероятностных алгоритмов. В основе подхода лежит т. н.
{\bf {\bf Лемма Шварца- Зиппеля}\footnote{
Смысл леммы в том, что если полином не равен нулю тождественно, то он
не может слишком часто обращаться в нуль, например, в точках целочисленной решетки. Это утверждение известно
как Schwartz-Zippel Lemma. На самом
деле, Шварцу, видимо, принадлежит вероятностная  интерпретация, поскольку сам факт давно известен
(см., например, главу ``Сравнения''  в книге Боревича и Шафаревича ``Теория чисел''), но ему
не придавали вероятностной интерпретации.}.


Пусть $f(x_1,\dots, x_n)$, не равный тождественно нулю 
полином степени не выше $k$ по каждой переменной\footnote{Лемма остается верной, если считать, что 
$k$~--- это суммарная степень по совокупности переменных.}, и пусть принимающие целые значения случайные величины 
$\xi_1,\dots, \xi_n$ независимо и равномерно 
распределены на отрезке $[0,N-1]$. 

Тогда $Prob\{f(\xi_1,\dots, \xi_n)=0\}\leq \frac{kn}N$.
}


Это утверждение мы обсудим на лекции, и на эту тему будут задачи как в ближайших
контрольных, так и в финальном тесте.

{\bf Доказательство леммы} {\em проводится индукцией по числу переменных $n$.
Утверждение верно при $n=1$, поскольку нетривиальный 
полином степени $k$ имеет не более $k$ корней. При $n>1$ разложим $f$ по переменной $x_1$:
$f=f_0+f_1 x_1+\ldots + f_t x_1^t$, где полиномы $f_0,\ldots, f_t$ не зависят от $x_1$, а $f_t$ не равен нулю
тождественно. Тогда по формуле полной вероятности $Prob\{f=0\}= Prob\{f=0 \mid f_t=0\} Prob\{f_t=0\} +  Prob\{f=0 \mid f_t\neq 0\} 
Prob\{f_t\neq 0\} \leq Prob\{f_t=0\} +  Prob\{f=0 \mid f_t\neq 0\}$. Первый член оценивается по индуктивному
предположению, а второй --- не больше, чем $\frac{k}{N}$, поскольку на каждом отрезке $[(0,\xi_2,\ldots,\xi_n),
(N-1,\xi_2,\ldots,\xi_n)]$ полином $f=f_0+f_1 x_1+\ldots + f_t x_1^t$ с ненулевым старшим коэффициентом 
$f_t$ может иметь не более $t\leq k$ корней, так что $Prob\{f=0\}\leq \frac{k(n-1)}{N}+ \frac{k}{N}$.}



}




\bigskip

\prp ($4 \times 0.01 $)
{\footnotesize
Проверьте матричное равенство $C=AB$, где $A,B,C$--
$n \times n$ матрицы, имеющие целочисленные элементы, не превышающие по
абсолютной величине $h$, используя рандомизацию.

Пусть $x$--- случайный $n$-мерный вектор,
компоненты которого независимые целые числа, равномерно выбранные из
интервала $[0,1,\dots,N-1]$. Проверка равенства состоит в вычислении
$A(Bx)=Cx$:  если это равенство  справедливо, то вы предполагаете, что
исходное равенство верное, иначе вы сигнализируете об ошибке.
Заметим, что каждую такую проверку можно выполнить за $O(n^2)$ операций
над $O(\log(nh^2))$-разрядными числами, 
а любой сигнал об ошибке говорит о том, что исходное равенство неверное.
С другой стороны, если проверка прошла успешно, то возможно, что исходное
равенство неверное, но мы неудачно подобрали тестовый вектор $x$. 
}

({\em i}) Каким нужно выбрать $N$, чтобы вероятность ошибки вашей
процедуры была меньше заданной вероятности $p$?

({\em ii}) Тот же вопрос, если разрешается проводить несколько
независимых проверок, а минимизировать нужно общую {\em битовую
сложность} вычислений.

({\em iii}) Сравните битовую сложность вероятностных
процедур с стандартным детерминированным алгоритмом перемножения матриц
для $n=10000; h=2^{15}; p=0.001$

({\em iv}) Для дальнейшей экономии вы
решили использовать проверку $(A(Bx)x)=(Cx)x$ или проверку
$(A(Bx)y)=(Cx)y$, где $n$-вектор $y$ выбирается независимо от $x$ и
имеет те же характеристики. Как изменится для этих случаев $N$?

\medskip
{\footnotesize
Язык 2-ВЫПОЛНИМОСТЬ состоит из выполнимых КНФ, в которых каждый дизъюнкт содержит не более двух литералов. Вы знаете, что задачу можно решать за линейное время, используя линейный алгоритм выделения сильно связных компонент в орграфах (об этом мы говорили на последней лекции). В этой задаче мы построим быстрый вероятностный алгоритм для проверки выполнимости 2-КНФ. Пусть 2-КНФ имеет $n$ литералов и 
$m$ дизъюнктов.

{\bf Алгоритм случайного поиска для языка 2-КНФ}. Сначала всем переменным присваивается значение TRUE. На каждой итерации, пока формула невыполнима, берется произвольный невыполненный дизъюнкт, в нем равновероятно выбирается произвольный литерал и его логическое значение обращается. Этот процесс напоминает случайное блуждание и в принципе может продолжаться бесконечно (например, если взять невыполнимую КНФ). Однако для выполнимой 2-КНФ можно получить полиномиальные оценки среднего числа итераций. Дело в том, что \emph{число отличий} между текущим набором логических значений переменных и их значениями в некотором произвольном (но фиксированном) выполняющем наборе (существующем по предположению) изменяется на каждой итерации с вероятностью $\frac12$ на 1. Таким образом, наш алгоритм можно интерпретировать как случайное блуждание на отрезке [0,1,…,n].
}

\prp ($0.04+0.01$)
($i$) Покажите, что для выполнимой 2-КНФ среднее число итераций алгоритма (математическое ожидание числа итераций) равно $O(n^2)$.

($ii$) Пусть пункт ($i$) справедлив (а больше ничего о языке 2-КНФ неизвестно). В какой из вероятностных классов, определенных выше, попадает тогда язык 2-КНФ?

\smallskip

{\footnotesize

Задача о минимальном разрезе в неориентированном графе $G=(V,E)$ заключается в том, чтобы разбить вершины графа на два дизъюнктных подмножества $(S,\bar S  ),\, S\neq V, \,S\neq \varnothing$ так, чтобы минимизировать число ребер с концами в разных долях. Конечно, для ее решения можно применить потоковый алгоритм, но мы рассмотрим простую вероятностную процедуру. При этом основной будет операция стягивания ребра (кратные ребра остаются, а петли удаляются). Граф, полученный стягиванием ребра $(x,y)\in E$, обозначим $G/(x,y)$. Первоначальная идея заключается в следующем: при стягивании ребер величина минимального разреза не убывает (пока в графе остается не менее двух вершин), так что если стянуть все ребра $\{e_1,…,e_p\}$, не входящие в минимальный разрез, то останется пара вершин, соединенная $k$ ребрами, где $k$~--- величина минимального разреза в $G$. Остается понять, как часто реализуется подобная ситуация, если ребра стягиваются случайно.
}

\prp ($2\times 0.02+0.01$)  ($i$) Покажите, что вероятность того, что случайно выбранное ребро в графе входит в минимальный разрез не превышает $\frac2{|V|}$.

{\footnotesize
Из предыдущей задачи вытекает следующий вероятностный алгоритм определения минимального разреза:

MINCUT $[G(V,E), |V|=n]$

$G_0\gets G;\, i\gets 0;$

{\bf while} $ |V(G_i)|>2$ {\bf do}

В $G_i$ выбираем случайное ребро $e_i$ (с равномерным распределением на ребрах $G_i$).

$G_{i+1}\gets G_/ e_i;\,  i\gets  i+1;$

{\bf end while}

\emph{Комментарий. На выходе из цикла получаем (мульти)граф $\tilde G$, имеющий две вершины, соединенные ребрами, иногда отвечающими разрезу в исходном графе.}

{\bf return} Разрез в исходном графе $G$, отвечающий разрезу в $\tilde G$.

Времы работы алгоритма $O(n^2)$.
}



\noindent ($ii$)  Покажите что MINCUT выдает минимальный разрез с вероятностью $\geq \frac2{n(n-1)}$.

\noindent ($iii$) Покажите, что если независимо повторить процедуру MINCUT $n^2$ раз, то минимальный разрез будет найден с вероятностью $>0.85$.

\smallskip

{\footnotesize
В следующей задаче мы покажем, что
если привлечь дополнительные соображения, то можно понизить трудоемкость до $O(n^2  \log^{O(1)}  n)$. При этом алгоритм столь же прост и допускает параллелизацию.

Описанная  выше процедура поиска минимального разреза
последовательно выбирает случайные ребра и стягивает их концы до тех пор, 
пока в графе не останутся две вершины, соединенные (кратными) ребрами. 
Если при выборе случайных ребер мы ни разу не выбирали ребра разреза, то мы получаем ответ.
Выше мы показали,  что вероятность на $i$-м шаге выбрать ребро, входящее в разрез, равна 
$p_i = \frac{2}{n-i}$, отсюда вероятность того, что за $i$ шагов не будет выбрано ни одно ребро, 
входящее в минимальный разрез (мы будем говорить, что выбранные {\em ребра не задевают разрез}), 
равна $P_i = (1- p_1)(1- p_2) \ldots (1-p_i)$. Мы хотим ускорить алгоритм.
 Заметим, что чем больше ребер мы стягиваем, 
	тем больше вероятность, что следующее 
	выбранное ребро заденет минимальный разрез. Поэтому новая идея, которую мы хотим исследовать, 
заключается в том, чтобы стягивать 
	ребра до какого-то порога, пока вероятность попадания в разрез еще достаточно мала, 
а дальше использовать рекурсию.
Из формулы для $P_i$ видно, что если стянуть
$n/2$ случайных ребер, то они с
вероятностью $\geq\frac14$ не заденут минимальный разрез.

%Обозначим $G \gets G/e$ операцию стягивания ребра $e$ в графе $G$ (петли удаляются) 

 Блок-схема нового алгоритма приведена ниже. Процедура использует подпрограмму 
{\sc СТЯГИВАНИЕ $(G,k)$}, которая стягивает ребра  до тех пор пока число вершин
не уменьшится ниже порога $k$ (при стягивании произвольного ребра число вершин уменьшается
на единицу). 

\fbox{
\parbox{6cm}{%
\noindent {\sc СТЯГИВАНИЕ $(G,k)$}\\
{\bf for} $i:=n$ {\bf downto} $k$

В $G$ выбираем случайное ребро  $e$ 

(с равномерным распределением

на ребрах).

$G \gets G/e$\\
{\bf endfor}\\
{\bf return} $G$}%
}
 \qquad
\fbox{
\parbox{7cm}{%
\noindent {\sc МИН-РАЗРЕЗ $(G)$}\\
{\bf if} в $G$ больше восьми вершин {\bf then}

Повторить $4$ раза процедуру

$X_1 \gets$ {\sc МИН-РАЗРЕЗ [СТЯГИВАНИЕ $(G,\frac{n}2)$]};

$X_2 \gets$ {\sc МИН-РАЗРЕЗ [СТЯГИВАНИЕ $(G,\frac{n}2)$]};

$X_3 \gets$ {\sc МИН-РАЗРЕЗ [СТЯГИВАНИЕ $(G,\frac{n}2)$]};

$X_4 \gets$ {\sc МИН-РАЗРЕЗ [СТЯГИВАНИЕ $(G,\frac{n}2)$]};

{\bf return} $\min\{X_1,X_2,X_3,X_4\}$


\noindent {\bf else} находим минимальный разрез вручную.}%
}
}

\smallskip
\extraprp ($0.01+0.01 + 0.04+0.01$)

\noindent ($i$) Запишите рекуррентную оценку сложности $T(n)$ вычисления функции
{\sc МИН-РАЗРЕЗ $(G)$} для графа с $|V|=n$ вершинами.

\noindent ($ii$)  Найдите $\Theta$-асимптотику $T(n)$ (для этого нужно сначала оценить трудоемкость процедуры {\sc СТЯГИВАНИЕ $(G,k)$}).




{\footnotesize
 Оценим теперь с какой вероятностью $\PP(n)$ алгоритм {\sc МИН-РАЗРЕЗ}$(G)$
выдает минимальный разрез
для графа $G$ с $n$ вершинами. 
Вероятность успеха равна вероятности того, что хотя бы один рекурсивный вызов дал корректный ответ.
Таким образом, получаем:
$\PP(n)=1-\left(1-\frac14\PP(\frac{n}2)\right)^4$, откуда следует, что
$\PP(n)\geq\PP(\frac{n}2)-\frac38 \PP(\frac{n}2)^2$. 
Cчитая, что $n$ является степенью двойки, обозначим $p_k=\PP(2^k)$.  По определению, $p_k$  равно вероятности успеха, 
если потребовалось $k$ рекурсивных вызовов процедуры {\sc МИН-РАЗРЕЗ}. 
В частности, $p_0=1$.
 
Получаем рекурсию 
$p_{k+1}=1-(1-\frac14p_k)^4$. Откуда, если раскрыть скобки, следует: $p_{k+1}\geq p_k-\frac38 (\p_k)^2$. 
}

\noindent ($iii$) Приведите как можно более точную оценку снизу рекурсии:
$p_0=1; p_{k+1}= p_k-\frac38 (p_k)^2$ вида $p_k=\Omega(f(k))$.

{\em Подсказка.} Предположите, что $p_{k+1}-p_k\approx \frac{dp}{dk}$, и оцените порядок
роста функции $p(k)$, а потом обоснуйте вашу гипотезу. 

\noindent ($iv$) Получите оценку числа итераций модифицированно вероятностного алгоритма поиска минимального разреза,  для получения заданной точности $\varepsilon$ и приведите оценку общего числа операций.











\smallskip



\extraprp ($0.01+0.03 + 0.01$) {\bf [Вероятностный алгоритм для языка ВЫПОЛНИМОСТЬ и дерандомизация].}
{\footnotesize Предположим, КНФ содержит $m$ дизъюнктов и в каждый дизъюнкт входит ровно $k$ литералов.
Пусть $X$~--- случайная величина, равная числу выполненных дизъюнктов, если
независимо и равновероятно приписать каждому литералу значения $0$ или $1$. Поскольку 
каждый дизъюнкт ложен лишь при одном значении литералов и  матожидания суммируются, то
математическое ожидание числа выполненных дизъюнктов равно: $E(X)=m(1-2^{-k})$.

Это значит, что существует логический набор, на котором выполнено не менее $E(X)$ дизъюнктов.
Далее, как и в случае с задачами из $\np$, возникает та же проблема. Мы знаем, что такой 
набор существует, но не знаем, как его найти, не используя полный перебор. 
В нашем случае, для нахождения искомого набора можно, во-первых, построить эффективный 
вероятностный алгоритм. И более того, можно провести дерандомизацию, т. е.
конвертировать вероятностную процедуру в детерминированную (не сильно увеличивая сложность). 
Последнее возможно далеко не всегда, и одним из центральных вопросов теории сложности является
соотношение между классами $\p$ и $\bp$, т. е. верно ли, что всякую процедуру из $\bp$ можно дерандомизировать? 

Алгоритм нахождения набора заключается в следующем.
Оценим вероятность события $p=Prob[X\geq m(1-2^{-k})]$ (т. е. что в КНФ {\em выполнено 
не менее $m(1-2^{-k})$ дизъюнктов}).  Для этого распишем математическое ожидание: 
$E(X)=\sum_{i=1}^m i*Prob[X=i] \leq [m(1-2^{-k})-1](1-p)+mp$. Отсюда
$p\geq (m2^{-k}+1)^{-1}$.

Такая оценка позволяет построить следующий вероятностный 
алгоритм для определения набора, выполняющего не менее $m(1-2^{-k})$ дизъюнктов:
достаточно независимо повторить процедуру $\geq m2^{-k}+1$ раз и тогда с вероятностью $>\frac12$ одна из
попыток даст искомый набор. 
}

\noindent ($i$) Будет ли предложенный алгоритм 1)  Лас-Вегас алгоритмом; 2) Монте-Карло алгоритмом; 3) ни тем, ни другим?

{\footnotesize 

Поскольку
порождение случайного набора требует $O(n)$ операций, а проверка числа выполненных дизъюнктов требует 
$O(mk)$ операций, то одна итерация  алгоритма занимает $O(m2^{-k}(mk+n))$

Теперь попробуем дерандомизировать процедуру.

Свяжем с каждым литералом $x_i$ случайную величину $Y_i$, принимающую равновероятно значения 
$0$ или $1$, и будем считать $\{Y_i\}, \, i=1,\dots, n$ независимыми. Значение величины $Y_i$ будем
обозначать маленькой буквой $y_i$. Мы используем  т.н. метод
{\em условных вероятностей}, который заключается в последовательном приписывании логических
значений литералам так, чтобы на каждом шаге выполнялось неравенство:
$E(X | y_1,\dots, y_j) \leq E(X | y_1,\dots, y_{j+1})$. Осуществить такой подход удается не всегда.
В нашем случае ключевым является тождество\footnote{На самом деле, достаточно потребовать
{\em квазивогнутости}: $E(X|\dots)\leq \max[E(X|\dots,Y_{j+1}=1), E(X|\dots,Y_{j+1}=0)]$.}:
$E(X | y_1,\dots, y_j)=\frac12[E(X | y_1,\dots, y_j,Y_{j+1}=1)+E(X | y_1,\dots, y_j,Y_{j+1}=0)]$.
Таким образом, нужно  научиться {\em детерминированно} приписывать литералу $x_{j+1}$ значение, 
имеющее {\em большее условное математическое ожидание}. Для этого нужно разбить множество дизъюнктов
на $4$ непересекающиеся подмножества  [1) уже выполненных; 2) не зависящих от $x_{j+1}$; 3) выполняющихся
при $x_{j+1}=1$; 4) выполняющихся при $x_{j+1}=0$], вычислить условные мат. ожидания  и присвоить 
литералу $x_{j+1}$ значение, отвечающее большему мат. ожиданию.
}

({\em ii}) Закончите вычисления, т. е. явно укажите, какие истинностные значения следует присваивать
литералам. При вычислении условных вероятностей не забывайте о вкладе переменных, значения которым 
{\bf еще не присвоены}!

({\em iii}) Проведите вычисления для $2$-КНФ\footnote{Контрольный вопрос: является ли  указанная процедура 
полиномиальным алгоритмом для $2$-КНФ?} $ (\bar x_2 \vee \bar x_3) \land (\bar
x_1 \lor  \bar x_6) \land (x_2 \lor \bar x_4 ) 
\land (\lor \bar x_5 \lor x_7)
\land (\bar x_7 \lor x_8 \lor ) \land (x_1 \lor \bar x_7 )$


{\footnotesize В заключение отметим, что по ходу рассуждений мы показали следующее полезное утверждение (которое полезно доказать каким-то иным способом):
\emph{всякая $k$-КНФ, имеющая меньше $2^k$ дизъюнктов, выполнима}.

Кроме того, \emph{для случая $3$-КНФ, каждый дизъюнкт которой содержит ровно $3$ литерала, 
мы построили $\frac78$-приближенный (детерминированный и вероятностный)
полиномиальный алгоритмы для $NP$-трудной задачи MAX-3-SAT, в которой требуется выполнить максимальное число
дизъюнктов\footnote{Это, значит, что алгоритм находит набор, на котором выполняется не менее $\frac78$ от максимально возможного числа дизъюнктов, которые можно одновременно выполнить. }.} И в этом бы не было ничего удивительного, если бы J.H\aa stad не показал (это довольно тяжело),
что при $\p\neq \np$ {\bf никакая} эффективная процедура для задачи MAX-ВЫПОЛНИМОСТЬ не может давать большую точность. 





\end{document}







